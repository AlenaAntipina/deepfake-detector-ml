{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\MlopsProject\\.conda\\python.exe\n",
      "d:\\MlopsProject\\.conda\\lib\\site-packages\\torch\\__init__.py\n",
      "False\n",
      "Collecting environment information...\n",
      "PyTorch version: 1.12.1\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: Could not collect\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Майкрософт Windows 10 Pro\n",
      "GCC version: Could not collect\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.26.0-rc6\n",
      "Libc version: N/A\n",
      "\n",
      "Python version: 3.7.16 (default, Jan 17 2023, 16:06:28) [MSC v.1916 64 bit (AMD64)] (64-bit runtime)\n",
      "Python platform: Windows-10-10.0.19041-SP0\n",
      "Is CUDA available: False\n",
      "CUDA runtime version: 11.6.55\n",
      "GPU models and configuration: GPU 0: NVIDIA GeForce GTX 1050\n",
      "Nvidia driver version: 531.14\n",
      "cuDNN version: Could not collect\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.18.5\n",
      "[pip3] torch==1.13.1\n",
      "[pip3] torchvision==0.14.1\n",
      "[conda] blas                      1.0                         mkl  \n",
      "[conda] mkl                       2021.4.0           haa95532_640  \n",
      "[conda] mkl-service               2.4.0            py37h2bbff1b_0  \n",
      "[conda] mkl_fft                   1.3.1            py37h277e83a_0  \n",
      "[conda] mkl_random                1.2.2            py37hf11a4ad_0  \n",
      "[conda] numpy                     1.18.5                   pypi_0    pypi\n",
      "[conda] pytorch                   1.12.1          cpu_py37h5e1f01c_1  \n",
      "[conda] torch                     1.13.1                   pypi_0    pypi\n",
      "[conda] torchvision               0.14.1                   pypi_0    pypi\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import torch\n",
    "print(torch.__file__) \n",
    "print(torch.cuda.is_available())\n",
    "from torch.utils import collect_env\n",
    "print(collect_env.main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10528\\3639984939.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda_version\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "print(torch.cuda_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4416\\3382769975.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\MlopsProject\\.conda\\lib\\site-packages\\torch\\cuda\\__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    209\u001b[0m                 \"multiprocessing, you must use the 'spawn' start method\")\n\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_cuda_getDeviceCount'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Torch not compiled with CUDA enabled\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_cudart\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             raise AssertionError(\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "torch.zeros(1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey\n"
     ]
    }
   ],
   "source": [
    "print(\"hey\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the average frame count \n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#change the path accordingly\n",
    "video_files = glob.glob(r\"D:\\MlopsProject\\dataset\\data\\manipulated_sequences\\Deepfakes\\c23\\videos\\*.mp4\")\n",
    "#video_files += glob.glob(r\"D:\\MlopsProject\\dataset\\data\\manipulated_sequences\\Face2Face\\c23\\videos\\*.mp4\")\n",
    "#video_files += glob.glob(r\"D:\\MlopsProject\\dataset\\data\\manipulated_sequences\\FaceSwap\\c23\\videos\\*.mp4\")\n",
    "#video_files += glob.glob(r\"D:\\MlopsProject\\dataset\\data\\manipulated_sequences\\NeuralTextures\\c23\\videos\\*.mp4\")\n",
    "video_files += glob.glob(r\"D:\\MlopsProject\\dataset\\data\\original_sequences\\youtube\\c23\\videos\\*.mp4\")\n",
    "\n",
    "#video_files = os.listdir(r\"D:\\MlopsProject\\dataset\\data\\manipulated_sequences\\Deepfakes\\c23\\videos\")\n",
    "#video_files += os.listdir(r\"D:\\MlopsProject\\dataset\\data\\manipulated_sequences\\Face2Face\\c23\\videos\")\n",
    "#video_files += os.listdir(r\"D:\\MlopsProject\\dataset\\data\\manipulated_sequences\\FaceSwap\\c23\\videos\")\n",
    "#video_files += os.listdir(r\"D:\\MlopsProject\\dataset\\data\\manipulated_sequences\\NeuralTextures\\c23\\videos\")\n",
    "#video_files += os.listdir(r\"D:\\MlopsProject\\dataset\\data\\original_sequences\\youtube\\c23\\videos\")\n",
    "\n",
    "print(len(video_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of videos:  2000\n",
      "Average frame per video: 509.128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "frame_count = []\n",
    "for video_file in video_files:\n",
    "  cap = cv2.VideoCapture(video_file)\n",
    "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150):\n",
    "    video_files.remove(video_file)\n",
    "    continue\n",
    "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "#print(\"frames\" , frame_count)\n",
    "print(\"Total number of videos: \" , len(frame_count))\n",
    "print('Average frame per video:',np.mean(frame_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract frame\n",
    "def frame_extract(path):\n",
    "  vidObj = cv2.VideoCapture(path) \n",
    "  success = 1\n",
    "  while success:\n",
    "      success, image = vidObj.read()\n",
    "      if success:\n",
    "          yield image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition in d:\\mlopsproject\\.conda\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: dlib>=19.7 in d:\\mlopsproject\\.conda\\lib\\site-packages (from face_recognition) (19.24.0)\n",
      "Requirement already satisfied: numpy in d:\\mlopsproject\\.conda\\lib\\site-packages (from face_recognition) (1.18.5)\n",
      "Requirement already satisfied: face-recognition-models>=0.3.0 in d:\\mlopsproject\\.conda\\lib\\site-packages (from face_recognition) (0.3.0)\n",
      "Requirement already satisfied: Pillow in d:\\mlopsproject\\.conda\\lib\\site-packages (from face_recognition) (9.4.0)\n",
      "Requirement already satisfied: Click>=6.0 in d:\\mlopsproject\\.conda\\lib\\site-packages (from face_recognition) (8.1.3)\n",
      "Requirement already satisfied: colorama in d:\\mlopsproject\\.conda\\lib\\site-packages (from Click>=6.0->face_recognition) (0.4.6)\n",
      "Requirement already satisfied: importlib-metadata in d:\\mlopsproject\\.conda\\lib\\site-packages (from Click>=6.0->face_recognition) (6.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in d:\\mlopsproject\\.conda\\lib\\site-packages (from importlib-metadata->Click>=6.0->face_recognition) (4.5.0)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\mlopsproject\\.conda\\lib\\site-packages (from importlib-metadata->Click>=6.0->face_recognition) (3.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MlopsProject\\.conda\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: [WinError 126] Не найден указанный модуль\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# process the frames\n",
    "def create_face_videos(path_list,out_dir):\n",
    "#  print(\"out_dir: \", out_dir)\n",
    "  already_present_count =  glob.glob(out_dir+'*.mp4')\n",
    "  print(\"No of videos already present \" , len(already_present_count))\n",
    "  for path_to_video in tqdm(path_list):\n",
    "    out_path = os.path.join(out_dir,path_to_video.split('\\\\')[-1])\n",
    "   # print(\"out_path \" , out_path)\n",
    "    file_exists = glob.glob(out_path)\n",
    "    if(len(file_exists) != 0):\n",
    "      print(\"File Already exists: \" , out_path)\n",
    "      continue\n",
    "    frames = []\n",
    "    flag = 0\n",
    "    face_all = []\n",
    "    frames1 = []\n",
    "    out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n",
    "    for idx,frame in enumerate(frame_extract(path_to_video)):\n",
    "      #if(idx % 3 == 0):\n",
    "      if(idx <= 150):\n",
    "        frames.append(frame)\n",
    "        if(len(frames) == 4):\n",
    "          faces = face_recognition.batch_face_locations(frames)\n",
    "          for i,face in enumerate(faces):\n",
    "            if(len(face) != 0):\n",
    "              top,right,bottom,left = face[0]\n",
    "            try:\n",
    "              out.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n",
    "            except:\n",
    "              pass\n",
    "          frames = []\n",
    "    try:\n",
    "      del top,right,bottom,left\n",
    "    except:\n",
    "      pass\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of videos already present  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ed5953579147f7a9514e93fd1cecff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_face_videos(video_files, \"D/MlopsProject/dataset/data/сut_videos/\")\n",
    "print(\"end\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.16 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f5357702cdd27a3f583ecb2f946a0ad797de19db46cdb0bcfe31dcbc7144696"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
